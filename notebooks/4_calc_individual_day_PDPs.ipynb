{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ff9e7-6025-4450-8b2d-52a1b34671c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir='/path/to/main_project_folder/' # edit this line\n",
    "\n",
    "nlag = 1\n",
    "SNOWFREE = True # remove DJF from training data\n",
    "\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.random import set_seed as tf_set_seed\n",
    "import tensorflow.compat.v1 as tf_compat_v1\n",
    "import random\n",
    "np.random.seed(101)\n",
    "random.seed(201)\n",
    "tf_set_seed(333)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(proj_dir)\n",
    "from project_utils import parameters as param\n",
    "from project_utils import load_region\n",
    "from project_utils import prepare_inputs\n",
    "from project_utils import utils as util\n",
    "from project_utils import model_utils as mu\n",
    "import importlib\n",
    "importlib.reload(param)\n",
    "importlib.reload(prepare_inputs)\n",
    "importlib.reload(util)\n",
    "importlib.reload(mu)\n",
    "importlib.reload(load_region)\n",
    "session_conf = tf_compat_v1.ConfigProto(device_count={'CPU': 24})\n",
    "sess = tf_compat_v1.Session(config=session_conf)\n",
    "import tensorflow.keras as keras\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c560ca0-3157-47be-b8a8-5af08cd38fb3",
   "metadata": {},
   "source": [
    "## calculate SM-T partial dependence plots for individual days (for use in Figure 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034c41b-dfe8-4def-bbd7-48513e88ee8f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_list = ['southcentral_north_america']\n",
    "\n",
    "ninputs = 2 # number of geospatial CNN input channels (i.e., GPH and SM)\n",
    "w = 200 # window size for smoothing PDP curve\n",
    "nlag = 1\n",
    "SNOWFREE = True # remove DJF from training data\n",
    "\n",
    "for dset in [\"ERA5\"]:\n",
    "    for jj in range(len(region_list)):\n",
    "        region_str = region_list[jj]\n",
    "        hem, region_input_lat_bbox, region_input_lon_bbox, region_box_x, region_box_y, region_lat, region_lon, region_lon_EW, region_t62_lats, region_t62_lons = load_region.load_region_constants(region_str)        \n",
    "        print(jj)\n",
    "        print(region_str)\n",
    "        print(hem)\n",
    "        print(w)\n",
    "\n",
    "        ### Read soilw data and sort\n",
    "        pred_temps = pd.read_csv(\"../processed_data_\"+dset+\"/\"+region_str+\"/model_predictions_lag\"+str(nlag)+\".csv\") \n",
    "\n",
    "        hgt_df = pd.read_csv(\"../processed_data_\"+dset+\"/\"+region_str+\"/region_avg_hgt.csv\")\n",
    "        hgt_df['time'] = pd.to_datetime(hgt_df['time'])\n",
    "        hgt_df_test = pd.read_csv(\"../processed_data_\"+dset+\"/\"+region_str+\"/region_avg_hgt.csv\")\n",
    "        hgt_df_test['time'] = pd.to_datetime(hgt_df_test['time'])\n",
    "\n",
    "        soilw_df = pd.read_csv(\"../processed_data_\"+dset+\"/\"+region_str+\"/region_avg_soilw_cday_anomaly.csv\")\n",
    "        soilw_df['time'] = pd.to_datetime(soilw_df['time'])\n",
    "        time_vec = soilw_df['time']\n",
    "\n",
    "        test_idx = pred_temps[pred_temps.set == 'test'].index.values  \n",
    "        print(pred_temps)\n",
    "        print(test_idx)\n",
    "        if SNOWFREE:\n",
    "            if hem == 'south':\n",
    "                print('removing JJA soilw maps')\n",
    "                soilw_df = soilw_df[(pd.to_datetime(time_vec).dt.month < 6) | (pd.to_datetime(time_vec).dt.month > 8)].iloc[:-1].reset_index(drop=True)\n",
    "                hgt_df = hgt_df[(pd.to_datetime(time_vec).dt.month < 6) | (pd.to_datetime(time_vec).dt.month > 8)].iloc[1:].reset_index(drop=True)\n",
    "                hgt_df_test = hgt_df_test[(hgt_df_test['time'].dt.month < 6) | (hgt_df_test['time'].dt.month > 8)].iloc[1:].reset_index(drop=True).loc[test_idx]\n",
    "            elif hem == 'north':\n",
    "                print('removing DJF soilw maps')\n",
    "                soilw_df = soilw_df[(pd.to_datetime(time_vec).dt.month >= 3) & (pd.to_datetime(time_vec).dt.month <= 11)].reset_index(drop=True)\n",
    "                hgt_df = hgt_df[(pd.to_datetime(time_vec).dt.month >= 3) & (pd.to_datetime(time_vec).dt.month <= 11)].reset_index(drop=True)\n",
    "                hgt_df_test = hgt_df_test[(hgt_df_test['time'].dt.month >= 3) & (hgt_df_test['time'].dt.month <= 11)].reset_index(drop=True).loc[test_idx]\n",
    "            print('hgt_df:', hgt_df)\n",
    "            print('hgt_df_test:', hgt_df_test)\n",
    "            print('soilw_df:', soilw_df)\n",
    "\n",
    "        sorted_hgt_df = hgt_df.sort_values(by='hgt_anom_no_trend')\n",
    "        sorted_hgt_df_test = hgt_df_test.sort_values(by='hgt_anom_no_trend')\n",
    "        sorted_soilw_df = soilw_df.sort_values(by='soilw_daily_anom')\n",
    "        print(sorted_hgt_df)\n",
    "        print(sorted_hgt_df_test)\n",
    "        print(sorted_soilw_df)\n",
    "\n",
    "        ### Sort soilw input maps in order of increasing avg soilw anomaly\n",
    "        input_dat, y_dat, ind, caldays, _time_vec = prepare_inputs.get_model_inputs(region_str, nlag, SNOWFREE, hemisphere=hem, dset=dset)\n",
    "        hgt_input_dat = input_dat[:, :, :, 0]\n",
    "        sorted_soilw_input_dat = input_dat[:,:,:,1][sorted_soilw_df.index.values, :, :]\n",
    "\n",
    "        ## build model and load weights ##\n",
    "        np.random.seed(101)\n",
    "        random.seed(201)\n",
    "        tf.random.set_seed(333)\n",
    "        ninputs = 2\n",
    "        ndense = 1\n",
    "        ncnn = 1\n",
    "        ncrp = 2\n",
    "        conv_filters = 8\n",
    "        dense_neurons = 32\n",
    "        curr_reg = 0.001\n",
    "        curr_loss = 'mean_squared_error'\n",
    "        SNOWFREE = True\n",
    "        curr_act_func = 'sigmoid'\n",
    "        curr_opt = 'RMSprop'\n",
    "        \n",
    "        model = mu.build_model(lr = 1.0, conv_filters=conv_filters,\n",
    "                               dense_neurons=dense_neurons, dense_layers = ndense, \n",
    "                               cnn_layers = ncnn, conv_relu_pool_layers = ncrp, \n",
    "                               activity_reg = curr_reg, input_channels = ninputs, \n",
    "                               loss_str=curr_loss, opt=curr_opt, \n",
    "                               act_func=curr_act_func, \n",
    "                               nlats=len(input_dat[0,:,0,0]), nlons=len(input_dat[0,0,:,0]))\n",
    "        \n",
    "        model.load_weights(\"../processed_data_\"+dset+\"/\"+region_str+\"/trained_weights\"+\"_lag\"+str(nlag)+\".h5\")\n",
    "        print(model.predict({\"stacked_input\" : input_dat, \"calday\": caldays}))\n",
    "\n",
    "        #############################################\n",
    "        # determine hgt days: high/med/low pressure #\n",
    "        #############################################\n",
    "        min_hgt_idx = sorted_hgt_df_test.index.values[0]\n",
    "        med_hgt_idx = sorted_hgt_df_test.index.values[int(np.floor(len(sorted_hgt_df_test)/2))]\n",
    "        max_hgt_idx = sorted_hgt_df_test.index.values[-1]\n",
    "        print(min_hgt_idx, med_hgt_idx, max_hgt_idx)\n",
    "        print(hgt_df.loc[min_hgt_idx])\n",
    "        print(hgt_df.loc[med_hgt_idx])\n",
    "        print(hgt_df.loc[max_hgt_idx])\n",
    "\n",
    "        ############################################\n",
    "        # determine hgt days: best hit / best miss #\n",
    "        ############################################\n",
    "        print(pred_temps)\n",
    "        best_hit = (pred_temps.predicted_tmax - pred_temps.true_y).loc[test_idx].abs().idxmin()\n",
    "        worst_miss = (pred_temps.predicted_tmax - pred_temps.true_y).loc[test_idx].abs().idxmax()\n",
    "        print((pred_temps.predicted_tmax - pred_temps.true_y).loc[test_idx][best_hit])\n",
    "        print((pred_temps.predicted_tmax - pred_temps.true_y).loc[test_idx][worst_miss])\n",
    "        hgt_day_idx = [min_hgt_idx, med_hgt_idx, max_hgt_idx, best_hit, worst_miss] \n",
    "        idx_titles = ['low pressure', 'median pressure', 'high pressure', 'best hit', 'worst miss'] \n",
    "\n",
    "        ########################################################\n",
    "        # ICE plots (Individual Conditional Expectation Plots) #\n",
    "        ########################################################\n",
    "        predict_df_daily = []\n",
    "        x_vec = sorted_soilw_df.soilw_daily_anom.values\n",
    "        ice_dict = {}\n",
    "        fig, axes = plt.subplots(len(hgt_day_idx),1,figsize=(8,20))\n",
    "        ax = axes.flatten()\n",
    "\n",
    "        for ii,hgt_day in enumerate(hgt_day_idx):\n",
    "            hgt_layer = hgt_input_dat[hgt_day, :, :].reshape(1, len(input_dat[0,:,0,0]), len(input_dat[0,0,:,0]))\n",
    "            hgt_input = np.tile(hgt_layer, [len(sorted_soilw_input_dat), 1, 1])\n",
    "            cday_input = np.tile(caldays[hgt_day], [len(sorted_soilw_input_dat), 1, 1])\n",
    "            pdp_input = np.stack((hgt_input, sorted_soilw_input_dat[:,:,:]), axis=3)\n",
    "\n",
    "            ########  model.predict #############\n",
    "            tmax_predictions = model.predict({\"stacked_input\" : pdp_input, \"calday\": cday_input})[:,0]\n",
    "            cumsum_vec = np.cumsum(np.insert(tmax_predictions, 0, 0)) \n",
    "            ma_vec = (cumsum_vec[w:] - cumsum_vec[:-w]) / w\n",
    "\n",
    "            ########  make the pdp plot ##########\n",
    "            ax[ii].scatter(x_vec, tmax_predictions, \n",
    "                       color = (68/255, 2/255, 86/255), s = 1.5, zorder = 0)\n",
    "            p = ax[ii].hist2d(x_vec, tmax_predictions, bins = 35, cmin = 10, \n",
    "                      norm = colors.LogNorm(), zorder = 5, cmap = \"twilight_shifted\");\n",
    "            ax[ii].scatter(x_vec[int(0.5*w):int(-0.5*w)],ma_vec[:-1], s=1, c='r', zorder=10)\n",
    "            ax[ii].scatter(soilw_df.soilw_daily_anom.iloc[hgt_day], pred_temps.true_y.iloc[hgt_day], s=60, c='lime', marker='*', zorder=10)\n",
    "            ax[ii].scatter(soilw_df.soilw_daily_anom.iloc[hgt_day], pred_temps.predicted_tmax.iloc[hgt_day], s=60, c='pink', marker='*', zorder=10)\n",
    "            ax[ii].set_title(idx_titles[ii]+'\\n'+str(sorted_soilw_df.time[hgt_day]))\n",
    "            ax[ii].set_xlabel('region avg soilw anomaly')\n",
    "            ax[ii].set_ylabel('Predicted TMAX (K)')\n",
    "\n",
    "            ice_dict[idx_titles[ii]] = {'hgt_day_idx': hgt_day.astype(float),\n",
    "                                                'hgt_layer': hgt_layer[0,:,:].tolist(),\n",
    "                                                'ice_x_vec' : x_vec[int(0.5*w):int(-0.5*w)].tolist(),\n",
    "                                                'ice_y_vec' : ma_vec[:-1].tolist(),\n",
    "                                                'soilw_vec' : x_vec.tolist(),\n",
    "                                                'Predicted TMAX' : tmax_predictions.tolist(),\n",
    "                                                'date' : str(sorted_soilw_df.time[hgt_day]),\n",
    "                                                'avg_sm' : soilw_df.soilw_daily_anom.iloc[hgt_day],\n",
    "                                                'reanalysis_tmax' :  pred_temps.true_y.iloc[hgt_day],\n",
    "                                                'model_predicted_tmax' :  pred_temps.predicted_tmax.iloc[hgt_day]}\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        import json\n",
    "        with open(\"../processed_data_\"+dset+\"/\"+region_str+\"/ice_plot_data_fig3.txt\", 'w') as f:\n",
    "            f.write(json.dumps(ice_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af096388-18cb-4de8-a342-b4030d99dc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cee9d09-cca8-4d03-bc98-dece86177347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a6a93-7457-47eb-9e42-062f48a8d418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9849d44-0be3-4a38-93bc-14ce196e1d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
